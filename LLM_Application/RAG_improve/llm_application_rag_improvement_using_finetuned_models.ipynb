{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7473dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위한 데이터셋을 불러와 1,000개만 선별\n",
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "klue_mrc_test = klue_mrc_test.train_test_split(test_size=1000, seed=42)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fdf404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩을 저장하고 검색하는 함수 구현\n",
    "import faiss\n",
    "\n",
    "def make_embedding_index(sentence_model, corpus):\n",
    "    embeddings = sentence_model.encode(corpus)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def find_embedding_top_k(query, sentence_model, index, k):\n",
    "    embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(embedding, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 인코더를 활용한 순위 재정렬 함수 정의\n",
    "import numpy as np\n",
    "\n",
    "def make_question_context_pairs(question_idx, indices):\n",
    "    return [[klue_mrc_test['question'][question_idx], klue_mrc_test['context'][idx]] for idx in indices]\n",
    "\n",
    "def rerank_top_k(cross_model, question_idx, indices, k):\n",
    "    input_examples = make_question_context_pairs(question_idx, indices)\n",
    "    relevance_scores = cross_model.predict(input_examples)\n",
    "    reranked_indices = indices[np.argsort(relevance_scores)[::-1]]\n",
    "    return reranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표(히트율)와 평가에 걸린 시간을 반환하는 함수 정의\n",
    "import time\n",
    "\n",
    "def evaluate_hit_rate(datasets, embedding_model, index, k=10):\n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "    for question in datasets['question']:\n",
    "        predictions.append(find_embedding_top_k(question, embedding_model, index, k)[0])\n",
    "    total_prediction_count = len(predictions)\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    contexts = datasets['context']\n",
    "\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if contexts[pred] == contexts[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 임베딩 모델로 평가\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "base_embedding_model = SentenceTransformer('Laseung/klue-roberta-base-klue-sts')\n",
    "base_index = make_embedding_index(base_embedding_model, klue_mrc_test['context'])\n",
    "evaluate_hit_rate(klue_mrc_test, base_embedding_model, base_index, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe437a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미세 조정한 임베딩 모델로 평가\n",
    "finetuned_embedding_model = SentenceTransformer('Laseung/klue-roberta-base-klue-sts-mrc-mnr-finetuned')\n",
    "\n",
    "finetuned_index = make_embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
